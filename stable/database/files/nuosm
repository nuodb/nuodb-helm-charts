#!/bin/bash

# (C) Copyright NuoDB, Inc. 2019-2021  All Rights Reserved
# This file is licensed under the BSD 3-Clause License.
# See https://github.com/nuodb/nuodb-helm-charts/blob/master/LICENSE

[ "$NUODB_DEBUG" = "verbose" ] && set -x
[ "$NUOSM_VALIDATE" = "true" ] && set -e

. ${NUODB_HOME}/etc/nuodb_setup.sh

: ${NUODB_ARCHIVEDIR:=/var/opt/nuodb/archive/${NUODB_DOMAIN}/${DB_NAME}}
: ${NUODB_BACKUPDIR:=/var/opt/nuodb/backup}
: ${NUODB_JOURNALDIR:=/var/opt/nuodb/journal/${NUODB_DOMAIN}/${DB_NAME}}
: ${NUODB_STORAGE_PASSWORDS_DIR:=/etc/nuodb/tde}
: ${NUODB_DOMAIN:="nuodb"}
: ${DB_NAME:="demo"}

liveness_req="/nuodb/nuosm/liveness"

DB_DIR=${NUODB_ARCHIVEDIR}
DB_PARENTDIR=$(dirname ${DB_DIR})

JOURNAL_DIR=${NUODB_JOURNALDIR}

LOGFILE=${NUODB_LOGDIR:=/var/log/nuodb}/nuosm.log
# since NuoDB 4.2.3, `nuodocker` has logging facilities to send logging to the
# AP; write the log from single nuosm execution to tmp file which content will
# be prepended to the rest of the database process statup logging
NUODB_EXTERNAL_STARTUP_LOG="$(mktemp /tmp/nuosm_startup.log.XXXXXX)"

myArchive=
restore_requested=
restore_source=
journal_flags=()

# attempt to retain the previous crash directory (within the configured window to avoid filling the disk)
crashcount=$(find $NUODB_CRASHDIR/core* -maxdepth 0 ! -type d 2>/dev/null | wc -l)
if [ $crashcount -ge 1 ]; then
  retainedcrashcount=$(find $NUODB_LOGDIR/crash-* -maxdepth 0 -type d -cmin -$OVERWRITE_WINDOW 2>/dev/null | wc -l)
  if [ $retainedcrashcount -lt $OVERWRITE_COPIES ]; then
    crashbackupdir="$NUODB_LOGDIR/crash-$( date +%Y%m%dT%H%M%S )/"
    mkdir $crashbackupdir
    mv $NUODB_CRASHDIR/core* $crashbackupdir
  fi
fi

export DB_NAME NUODB_STORAGE_PASSWORDS_DIR NUODB_EXTERNAL_STARTUP_LOG

#=======================================
# function - report an error and exit
#
function die() {
  local retval=$1
  shift
  error="$@"
  [ -n "$wotIdid" ] && error="Error while ${wotIdid}: ${error}"
  logWithLevel "ERROR" "$error"

  exit $retval
}

#=======================================
# function - log messages log level specified
#
function logWithLevel() {
  local level="$1"
  shift
  local message="$@"
  if [ -n "$message" ]; then
    printf '%s %-5s [:%s] nuosm %s\n' "$( date "+%Y-%m-%dT%H:%M:%S.%3N%z" )" "$level" "$HOSTNAME" "$message" | \
      tee -a "$LOGFILE" "$NUODB_EXTERNAL_STARTUP_LOG"
  fi
}

#=======================================
# function - log messages
#
function log() {
  logWithLevel "INFO" "$@"
}

#=======================================
# function - trace workflow
#
function trace() {
  wotIdid="$@"
  [ -n "$1" -a -n "$NUODB_DEBUG" ] && logWithLevel "DEBUG" "$wotIdid"
}

#=======================================
# function - wrap a log file around so it doesn't grow infinitely
#
function wrapLogfile() {
  logsize=$( du -sb $LOGFILE | grep -o '^ *[0-9]\+' )
  maxlog=5000000
  log "logsize=$logsize; maxlog=$maxlog"
  if [ ${logsize:=0} -gt $maxlog ]; then
    lines=$(wc -l $LOGFILE)
    tail -n $(( lines / 2 )) $LOGFILE > ${LOGFILE}-new
    rm -rf $LOGFILE
    mv $LOGFILE-new $LOGFILE
    log "(nuosm) log file wrapped around"
  fi
}

#=======================================
# function - checks if URL is provided in a form of scheme:[//authority]path
#
function isUrl() {
  local url="$1"
  echo "$url" | grep -q '^[a-z]\+:/[^ ]\+'
  return $?
}

#=======================================
# function - checks if backupset directory exist in case a backupset is proveded
# as restore source
#
function isRestoreSourceAvailable() {
  local source="$1"
  isUrl "$source" || [ -d "$NUODB_BACKUPDIR/$source" ]
  return $?
}

#=======================================
# function to perform archive restore
#
# If the restore is successful:
# * the archive dir contents will have been copied in;
# * the archive dir metadata will have been reset;
# * a new corresponding archive object will have been created in Raft.
#
# On error, any copy of the replaced archive is retained.
#
function perform_restore() {

  local restore_credentials="$(printf "%s" "${restore_credentials_encoded}" | base64 -d)"
  local retval=0
  local archSize=
  local archSpace=
  local saveName=
  local undo=
  local tarfile=
  local download_dir=
  local curl_creds=

  # Global variable used to hold the restore error message
  error=

  log "Restoring $restore_source; existing archive directores: $( ls -l $DB_PARENTDIR )"

  # work out available space
  archSize="$(du -s $DB_DIR | grep -o '^ *[0-9]\+')"
  archSpace="$(df --output=avail $DB_DIR | grep -o ' *[0-9]\+')"

  if [ $(( archSpace > archSize * 2)) ]; then
    saveName="${DB_DIR}-save-$( date +%Y%m%dT%H%M%S )"
    undo="mv $saveName $DB_DIR"
    mv $DB_DIR $saveName

    retval=$?
    if [ $retval -ne 0 ]; then
      $undo
      error="Error moving archive in preparation for restore"
      return $retval
    fi
  else
    tarfile="${DB_DIR}-$( date +%Y%m%dT%H%M%S ).tar.gz"
    tar czf $tarfile -C $DB_PARENTDIR $(basename $DB_DIR)

    retval=$?
    if [ $retval -ne 0 ]; then
      rm -rf $tarfile
      error="Restore: unable to save existing archive to TAR file"
      return $retval
    fi

    archSpace="$(df --output=avail $DB_DIR | grep -o ' *[0-9]\+')"
    if [ $(( archSize + 1024000 > archSpace )) ]; then
      rm -rf $tarfile
      error="Insufficient space for restore after archive has been saved to TAR."
      return 1
    fi

    undo="tar xf $tarfile -C $DB_PARENTDIR"
    rm -rf $DB_DIR
  fi

  mkdir $DB_DIR

  log "(restore) recreated $DB_DIR; atoms=$( ls -l $DB_DIR/*.atm 2>/dev/null | wc -l)"

  # restore request is a URL - so retrieve the backup using curl
  if isUrl "$restore_source"; then

    # define the download directory depending on the type of source
    if [ "$restore_type" = "stream" ]; then
      download_dir=$DB_DIR
    else
      # It is a backupset so switch the download to somewhere temporary available on all SMs (it will be removed later)
      # This will also run if TYPE is unrecognised, since it works for either type, but will be less efficient.
      download_dir=$(basename $restore_source)
      download_dir="${DB_PARENTDIR}/$(basename $download_dir .${download_dir#*.})-downloaded"
      mkdir $download_dir
    fi

    [ -n "$restore_credentials" -a "$restore_credentials" != ":" ] && curl_creds="--user $restore_credentials"
    [ -n "$curl_creds" ] && curl_opts="--user *:*"

    log "curl -k $curl_opts $restore_source | tar xzf - --strip-components $strip_levels -C $download_dir"
    curl -k $curl_creds "$restore_source" | tar xzf - --strip-components $strip_levels -C $download_dir

    retval=$?
    if [ $retval -ne 0 ]; then
      $undo
      error="Restore: unable to download/unpack backup $restore_source"
      return $retval
    fi

    chown -R "$(id -u):$(id -g)" "$download_dir"

    # restore data and/or fix the metadata
    log "restoring archive and/or clearing restored archive physical metadata"

    # if download is an archive, and not a backup then rename $download_dir to $DB_DIR
    # as if download was streamed instead.
    if [ "$restore_type" != "stream" ] && [ -f "$download_dir/1.atm" ]; then
      rmdir $DB_DIR
      mv $download_dir $DB_DIR
      download_dir=$DB_DIR
    fi

    status="$(nuodocker restore archive \
      --origin-dir $download_dir \
      "${journal_flags[@]}" \
      --restore-dir $DB_DIR \
      --db-name $DB_NAME \
      --clean-metadata 2>&1)"
    retval=$?
    log "$status"

    if [ "$SEPARATE_JOURNAL" == "true" ] && [ -f "$download_dir/1.atm" ]; then
      # `nuodocker restore archive` doesn't invoke `nuoarchive` on cold archive
      # (stream) restore type. Move the content of the internal journal
      # directory to the external journal path manually as the journal is not
      # consumed during SM shutdown
      log "Moving restored journal content to $JOURNAL_DIR"
      mv "$download_dir/journal/"* "$JOURNAL_DIR"
      chown -R "$(id -u):$(id -g)" "$JOURNAL_DIR"
    fi

    if [ "$download_dir" != "$DB_DIR" ]; then
      log "removing $download_dir"
      rm -rf $download_dir
    fi

  else
    # log "Calling nuoarchive to restore $restore_source into $DB_DIR"
    log "Calling nuodocker to restore $restore_source into $DB_DIR"
    status="$(nuodocker restore archive \
      --origin-dir $NUODB_BACKUPDIR/$restore_source \
      "${journal_flags[@]}" \
      --restore-dir $DB_DIR \
      --db-name $DB_NAME \
      --clean-metadata 2>&1)"
    retval=$?
    log "$status"
  fi

  if [ $retval -ne 0 ]; then
    $undo
    error="Restore: unable to restore source=$restore_source type=$restore_type into $DB_DIR"
    return $retval
  fi

  if [ -n "$restore_requested" ] && [ "$myArchive" -ne "-1" ]; then
    # complete restore request for this archive in retry loop because there
    # could be concurrent requests due to all archives restored at the same time
    retry 5 completeRestoreRequest "$myArchive"
    retval=$?
    if [ $retval -ne 0 ]; then
      $undo
      error="Restore: unable to complete restore request for archiveId=$myArchive"
      return $retval
    fi
    log "Restore request for archiveId=${myArchive} marked as completed"
  else
    purgeArchive "$myArchive"
  fi

  [ -n "$NUODB_DEBUG" ] && ls -l $DB_DIR

  return 0
}

#=======================================
# function - retry the provided function
#
# Retry the passed function with arguments until succees or max retry count is
# reached.
#
function retry() {
  local max="$1"
  shift
  local count=0
  local rc=0
  while [ "$count" -lt "$max" ]; do
    [ $count -gt 0 ] && log "'$*' exited with code $rc - retrying ..."
    "$@"
    rc=$?
    if [ $rc -eq 0 ]; then
      return $rc
    fi
    count=$(( count + 1 ))
    sleep 1
  done
  return $rc
}

#=======================================
# function - removes an archive metadata with `--purge` from the admin layer
#
function purgeArchive() {
  local archive_id="$1"
  if [ -n "$archive_id" ] && [ "$archive_id" -ne "-1" ]; then
    trace "completely deleting the raft metadata for archiveId=${archive_id}"
    log "Purging archive metadata archiveId=$archive_id"
    log "$( nuocmd delete archive --archive-id "$archive_id" --purge 2>&1 )"
  fi
}

#=======================================
# function - completes archive restore request
#
function completeRestoreRequest(){
  local archive_id="$1"
  local error
  trace "completing restore request for archiveId=${archive_id}"
  nuodocker complete restore --db-name "$DB_NAME" --archive-ids "$archive_id"
  return $?
}

#=======================================
# function - prints the latest backup group in which this SM participate
#
function getMyBackupGroup() {
  local group
  group=$(nuobackup --type report-groups --db-name "$DB_NAME" 2>/dev/null | grep "$POD_NAME" | awk '{print $1}')
  echo "${group:-UNKNOWN_BACKUP_GROUP}"
}

#=======================================
# function - resolves :latest or :group-latest backup source and stores it
# directly into restore_source variable. It is needed only when performing auto
# restore as nuorestore script already resolved these
#
function resolveLatestSource() {
  local latest_group
  local latest
  local my_group
  if [ "$restore_source" != ":latest" ] && [ "$restore_source" != ":group-latest" ]; then
    return 0
  fi

  my_group="$(getMyBackupGroup)"
  if [ "$restore_source" == ":latest" ]; then
    # find which backup group performed the latest backup
    trace "retrieve :latest using nuobackup"
    latest_group=$( nuobackup --type report-latest --db-name "$DB_NAME" )

    if [ -z "$latest_group" ] || [ "$latest_group" != "$my_group" ]; then
      # we can't restore this archive from a backup made by a different backup
      # group as it won't be available locally
      log "Latest backup is performed from different backup group ${latest_group}"
      return 1
    fi
  fi

  trace "retrieving latest backup for group ${my_group} using nuobackup"
  latest=$( nuobackup --type report-latest --db-name "$DB_NAME" --group "$my_group" )
  if [ -z "$latest" ]; then
    return 1
  fi
  log "Latest restore for $my_group resolved to $latest"
  restore_source="$latest"
  return 0
}

#=======================================
# function - Test that a backup file (the first argument) exists and contains
# the value of $BACKUP_ID
#
function checkBackupId() {
  local backup_file=$1
  [ -f $backup_file ] && [ "$(cat $backup_file | tr -d [:space:])" == "$BACKUP_ID" ]
}

#=======================================
# function - Looks for a previous archive and journal and imports it
#
function loadFromSnapshot() {
  local recreate_archives="false"

  if [ ! -f "$DB_DIR/state.dat" ]; then
    local archives=$( find "/var/opt/nuodb/archive" -name info.json )
    if [ -z "$archives" ] || [ $(echo "$archives" | wc -l) != 1 ]; then 
      die 1 "Did not find exactly 1 archive: ${archives}"
    fi

    local archive_path=$( dirname $archives )
    log "Found snapshot at ${archive_path}"

    if [ -n "$BACKUP_ID" ]; then
      if ! checkBackupId ${archive_path}/backup.txt ; then
        die 1 "Incorrect backup id in archive"
      fi
    fi

    if [ "$SEPARATE_JOURNAL" == "true" ]; then
      local relative_archive=$(realpath --relative-base=/var/opt/nuodb/archive $archive_path)
      local expected_journal="/var/opt/nuodb/journal/${relative_archive}"

      if [ ! -d $expected_journal ]; then
        die 1 "Did not find a journal snapshot at '$expected_journal'"
      fi
      
      if [ -n "$BACKUP_ID" ]; then
        if ! checkBackupId ${expected_journal}/backup.txt ; then
          die 1 "Incorrect backup id in journal"
        fi
      fi

      rm -rf ${JOURNAL_DIR}
      mv ${expected_journal} ${JOURNAL_DIR}

    fi

    # Don't move the archive until after we have done error checking.
    # Once we move the archive, we are going to be in the `archive already exists` branch
    # when kubernetes retries/restarts the pod.
    rm -rf ${DB_DIR}
    mv ${archive_path} ${DB_DIR}

    local recreate_archives="true"
  else
    trace "archive already exists, not looking for snapshot archives"

    local backup_file=${DB_DIR}/backup.txt
    if [ -n "$BACKUP_ID" ] && [ -f  $backup_file ] ; then
      if [ "$(cat $backup_file | tr -d [:space:])" == "$BACKUP_ID" ] ; then
        local recreate_archives="true"
      else
        log "Archive present but with a wrong backupId. Did the SM crash during a snapshot?"
      fi
    fi
  fi

  if [ $recreate_archives == "true" ]; then
    log "Removing outdated archive metadata"
    rm ${DB_DIR}/info.json ${DB_DIR}/backup.txt
    [ -e ${JOURNAL_DIR}/backup.txt ] && rm ${JOURNAL_DIR}/backup.txt
  fi
}

#=============================
# main routine
#=============================

log "==========================================="

wrapLogfile

# ensure DB_DIR exists
if [ ! -e "${DB_DIR}" ] ; then
  mkdir -p "${DB_DIR}"
  log "Created new dir $DB_DIR"
else
  log "Directory $DB_DIR exists"
fi

if [ "$SEPARATE_JOURNAL" == "true" ]; then
  if [ ! -e "${JOURNAL_DIR}" ] ; then
    mkdir -p "${JOURNAL_DIR}"
    log "Created new journal dir $JOURNAL_DIR"
  else
    log "Directory $JOURNAL_DIR exists"
  fi
  journal_flags+=("--journal-dir")
  journal_flags+=("${JOURNAL_DIR}")
  log "journal-dir=${JOURNAL_DIR}"
fi

if [ "$SNAPSHOT_RESTORED" == "true" ]; then
  loadFromSnapshot
fi

# Retry the first request against the admin layer to make sure that Raft
# commands can be committed and fail fast on error
retry 3 nuocmd get value --key "$liveness_req" 2>&1
if [ $? -ne 0 ]; then
  die 1 "NuoDB Admin layer liveness check failed"
fi

[ -f "$DB_DIR/info.json" ] && myArchive=$(sed -e 's|.*"id":\s*\([0-9]\+\).*|\1|' "$DB_DIR/info.json")
trace "checking archive raft metadata"
[ -z "$myArchive" ] && myArchive=$( nuocmd show archives \
  --db-name $DB_NAME \
  --archive-format "archive-id: {id}" | sed -En "/^archive-id: / {N; /$HOSTNAME/ s/^archive-id: ([0-9]+).*$/\1/; T; p}" | head -n 1 )
[ -z "$myArchive" ] && myArchive=$( nuocmd show archives \
  --db-name $DB_NAME \
  --removed --removed-archive-format "archive-id: {id}" | sed -En "/^archive-id: / {N; /$HOSTNAME/ s/^archive-id: ([0-9]+).*$/\1/; T; p}" | head -n 1 )
[ -z "$myArchive" ] && myArchive="-1"
log "archiveId=$myArchive; DB=$DB_NAME; hostname=$HOSTNAME"
[ -n "$NUODB_DEBUG" ] && [ "$myArchive" -eq "-1" ] && log "$(nuocmd show archives --db-name $DB_NAME)"

atomCount=$( ls -l $DB_DIR/*.atm 2>/dev/null | wc -l )
catalogCount=$( ls -l $DB_DIR/*.cat 2>/dev/null | wc -l )

log "path=$DB_DIR; atoms=${atomCount}; catalogs=${catalogCount}"

if [ "$myArchive" -ne "-1" ]; then
  trace "reading restore request for archiveId=${myArchive}"
  restore_requested=$(nuodocker get restore-requests --db-name "$DB_NAME" --archive-ids "$myArchive")
  restore_type="$(echo "$restore_requested" | awk '{print $2}')"
  user_data="$(echo "$restore_requested" | awk '{print $3}')"

  if [ -n "$restore_requested" ]; then
    if [ "$restore_type" == "automatic" ]; then
      # automatic restore for this archive has been requested
      log "Archive with archiveId=${myArchive} has been requested for a restore"
      trace "evaluating restore request data"
      eval "$user_data"
      if [ -z "$restore_source_encoded" ]; then
        # restore_source_encoded variable should be passed in the user_data by
        # `nuorestore` script
        die 1 "restore source is missing from restore request for archiveId=${myArchive}, userData='${user_data}'"
      fi
      restore_source="$(printf "%s" "${restore_source_encoded}" | base64 -d)"
      resolveLatestSource || die 1 "unable to resolve ${restore_source} restore source"
      # restore chart doesn't have notion of stream|backupset
      # `nuodocker restore archive` works with both
      restore_type="backupset"
      [ -z "$restore_credentials_encoded" ] && restore_credentials_encoded="$(printf "%s" "${DATABASE_RESTORE_CREDENTIALS:-:}" | base64 -w 0)"
      [ -z "$strip_levels" ] && strip_levels=${DATABASE_RESTORE_STRIP_LEVELS:-1}

      log "Archive restore will be performed for archiveId=${myArchive}, source=${restore_source}, type=${restore_type}, strip=${strip_levels}"
      trace "performing restore for archiveId=${myArchive}"
      if isRestoreSourceAvailable "$restore_source"; then
        perform_restore || die $? "$error"
      else
        error="Backupset $restore_source cannot be found in $NUODB_BACKUPDIR"
        die 1 "$error"
      fi
    fi
  elif [ "$atomCount" -lt 20 ] && [ "$catalogCount" -lt 2 ]; then
    if [ -n "$NUODB_AUTO_RESTORE" ]; then
      # autoRestore is configured, try to REPAIR the disk archive
      restore_source="$NUODB_AUTO_RESTORE"
      resolveLatestSource || log "unable to resolve ${restore_source} restore source"
      restore_credentials_encoded="$(printf "%s" "${DATABASE_RESTORE_CREDENTIALS:-:}" | base64 -w 0)"
      restore_type="${NUODB_AUTO_RESTORE_TYPE}"
      strip_levels="${NUODB_RESTORE_STRIP_LEVELS:-1}"

      log "Automatic archive repair will be performed for archiveId=${myArchive}, source=${restore_source}, type=${restore_type}, strip=${strip_levels}"
      trace "restoring damaged archive"
      if isRestoreSourceAvailable "$restore_source"; then
        perform_restore || die $? "$error"
      else
        log "restore source ${restore_source} is not available: skipping automatic archive repair"
      fi
      # delete damaged archive metadata as a new one will be created by
      # nuodocker start sm
      [ ! -f "$DB_DIR/info.json" ] && purgeArchive "$myArchive"
    fi
  fi
elif [ ! -f "$DB_DIR/1.atm" ] && [ ! -d "$DB_DIR/1.cat" ]; then
  if [ -n "$NUODB_AUTO_IMPORT" ] && isRestoreSourceAvailable "$NUODB_AUTO_IMPORT"; then
    trace "checking for database restore request"
    database_restore_requested=$(nuodocker get restore-requests --db-name "$DB_NAME" | grep "^Database ${DB_NAME} restore requested")
    if [ -z "$database_restore_requested" ]; then
      # autoImport is configured, try to IMPORT the disk archive
      restore_source="$NUODB_AUTO_IMPORT"
      restore_credentials_encoded="$(printf "%s" "${DATABASE_IMPORT_CREDENTIALS:-:}" | base64 -w 0)"
      restore_type=${NUODB_AUTO_IMPORT_TYPE}
      strip_levels=${NUODB_IMPORT_STRIP_LEVELS:-1}

      log "Automatic archive import will be performed for archiveId=${myArchive}, source=${restore_source}, type=${restore_type}, strip=${strip_levels}"
      trace "restoring empty archive"
      perform_restore || die $? "$error"
    else
      log "${database_restore_requested}: skipping automatic archive import"
    fi
  fi
fi

log "$( nuocmd show archives --db-name $DB_NAME )"

trace "executing nuodocker to start SM"

nuodocker_flags=()
[ -n "$NUODB_DEBUG" ] && nuodocker_flags+=("--debug")

# expects NUOCMD_API_SERVER to be set.
if [ -n "${NUODB_OPTIONS}" ] ; then
    exec nuodocker "${nuodocker_flags[@]}" start sm --archive-dir "${DB_DIR}" "${journal_flags[@]}" --dba-user "${DB_USER}" --dba-password "${DB_PASSWORD}" --db-name "${DB_NAME}" --options "${NUODB_OPTIONS}" "$@"
else
    exec nuodocker "${nuodocker_flags[@]}" start sm --archive-dir "${DB_DIR}" "${journal_flags[@]}" --dba-user "${DB_USER}" --dba-password "${DB_PASSWORD}" --db-name "${DB_NAME}" "$@"
fi