## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry and imagePullSecrets
##
# global:
#   imageRegistry: myRegistryName
#   imagePullSecrets:
#     - myRegistryKeySecretName

cloud:
  # supported: amazon, azure, google
  provider:
  # zones:
  #   - us-east-2a
  #   - us-east-2b
  #   - us-east-2c

  cluster:
    # cluster name is used to make resources unique in multi-cluster configurations.
    # If the NuoDB domain spans 2 or more physical clusters, then each cluster must have a unique cluster.name
    # and the entrypointName should be used to specify which name is used as the entrypoint.
    # The default is fine for single-cluster domains.
    name: cluster0
    entrypointName: cluster0

    # cluster domain is that specified during kubernetes deployment.  In multi-cluster configurations, it is
    # necessary to specify which cluster domain is used as the NuoDB Domain Entrypoint, and change it for the other clusters.
    # Defaults to cluster.local if omitted
    domain: cluster.local
    entrypointDomain: cluster.local

busybox:
  image:
    registry: docker.io
    repository: busybox
    tag: latest
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
    ##
    # pullSecrets:
    #   - myRegistryKeySecretName
    ## Specify a imagePullPolicy
    ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
    ##

nuodb:
  image:
    registry: docker.io
    repository: nuodb/nuodb-ce
    tag: 4.3.2
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
    ##
    # pullSecrets:
    # - myRegistryKeySecretName
    ## Specify a imagePullPolicy
    ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
    ##

  # the name of the ServiceAccount to use for all NuoDB Pods
  serviceAccount: nuodb

  # unless set to false, a new service account will be created
  addServiceAccount: true

  # unless set to false, a Role and RoleBinding named "nuodb-kube-inspector"
  # that grants access to Pods, PersistentVolumeClaims, PersistentVolumes, and
  # StatefulSets is added to nuodb.serviceAccount
  addRoleBinding: true

admin:
  # nameOverride: east
  # fullnameOverride: admin-east

  # domain is the name of the NuoDB administration domain (e.g. the cluster name)
  domain: nuodb
  # namespace: nuodb

  # replicas
  # Number of admin service pods. Requires 1 server available for each
  # Admin Service
  replicas: 1

  # If specified and set to a value greater than 0, an initial membership
  # consisting of server IDs <statefulset name>-0, <statefulset name>-1, ...,
  # <statefulset name>-<n-1> is defined for all Admins. Defining this to a
  # value larger than 1 allows a bootstrap server (e.g. <statefulset name>-0)
  # that has to be reprovisioned from scratch to rejoin its peers when it is
  # restarted, rather than bootstrapping a new domain consisting of itself.
  #
  # For multi-cluster configurations, only the Admin StatefulSet in the
  # entrypoint cluster (i.e. the one with cloud.cluster.name equal to
  # cloud.cluster.entrypointName) can specify bootstrapServers.
  #
  # Changing the value of bootstrapServers on a existing domain, either by
  # reinstantiating the Helm chart with a new value or by updating the 
  # corresponding nuodb.com/bootstrap-servers annotation or bootstrapServers label 
  # on an existing Admin StatefulSet, is illegal because
  # the domain can only be bootstrapped once. When upgrading nuodb-helm-charts
  # from a version that does not support bootstrapServers, bootstrapServers
  # must be set to 0.
  bootstrapServers: 1

  ## Global load balancer configuration for NuoAdmin
  ## Policy names for named policies should contain lowercase alphabetical 
  ## characters, numbers and hyphens.
  lbConfig:
    prefilter: ""
    default: ""
    fullSync: false
    policies:
      nearest: random(first(label(pod ${pod:-}) label(node ${node:-}) label(zone ${zone:-}) any))

  lbPolicy: nearest
  lbQuery: random(first(label(pod ${pod:-}) label(node ${node:-}) label(zone ${zone:-}) any))

  ## Enable the Layer 4 Load balancer if required,
  ## and specify if it should provision an internal or external cloud IP address
  externalAccess: {}
  #   enabled: false
  #   internalIP: true
  #   type: LoadBalancer
  #   annotations: {}

  # Enable NuoDB external access via Ingress; the provisioned Ingress controller
  # should support SSL passthrough feature allowing it to send the TLS
  # connections directly to the NuoDB Admin instead of decrypting the
  # communication; supported starting with Kubernetes v1.19.0
  ingress:
    enabled: false
    api:
      # the fully qualified domain name (FQDN) of the network host for the NuoDB
      # Admin REST API
      hostname: ""
      # the associated IngressClass name defines which controller will implement
      # the resource; for Kubernetes >= 1.18 the ingress class name should be
      # specified via the className option instead of using annotation
      className: ""
      # custom annotations that are set on the Ingress resource
      annotations: 
        ingress.kubernetes.io/ssl-passthrough: "true"
    sql:
      # the fully qualified domain name (FQDN) of the network host for SQL
      # clients
      hostname: ""
      # For Kubernetes >= 1.18 the ingress class name should be specified via the
      # ingressClassName option instead of using annotation
      className: ""
      # custom annotations that are set on the Ingress resource; SSL passthrough
      # feature should be configured so that SQL clients TLS connections are
      # send directly to the  NuoDB Admin
      annotations: 
        ingress.kubernetes.io/ssl-passthrough: "true"

  persistence:
    size: 1Gi
    accessModes:
      - ReadWriteOnce
    # storageClass: "-"

  ## Enable persistent volumes to retain logs when an external logging solution is not used.
  logPersistence:
    enabled: false
    overwriteBackoff:
      # Copies of the crash directory are taken to avoid overwrites of root crash.
      # This controls the window within which no more copies of the crash directory will be taken to avoid the disk filling.
      # Default will retain 3 copies within the last 120 minutes, after which copies will continue to be created.
      copies: 3
      windowMinutes: 120
    size: 60Gi
    accessModes:
      - ReadWriteOnce
    # storageClass: "-"

  # The name of the PriorityClass that admin pods should belong to. For more
  # information on PriorityClasses, see
  # https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/
  priorityClass: ""

  initContainers:
    # Whether to run init-disk init container to change permissions of mounted
    # volumes. This should not be necessary if fsGroup is being specified in
    # the security context, unless the volumes have a storage class that does
    # not support fsGroup, such as hostpath.
    runInitDisk: true

    # Whether to run init-disk as root. If set to false, the user defined by
    # the Pod security context will be used if one is defined, otherwise the
    # default user for the init-disk container image (busybox) will be used.
    runInitDiskAsRoot: true

  securityContext:
    # Whether to create a security context for Pods containing only the fsGroup
    # value defined below. This is less restrictive than runAsNonRootGroup,
    # because it allows all containers in the Pod, including init and sidecar
    # containers to run using the default user (assuming that the containers
    # does not explicitly specify runAsUser and runAsGroup in their own
    # security contexts).
    fsGroupOnly: false

    # Whether to create a security context for Pods restricting the uid and gid
    # of the runtime "nuodb" user to 1000:1000, which is supported starting
    # with NuoDB image version 4.3.
    #
    # runAsNonRootGroup must be set to false with NuoDB image versions older
    # than 4.3.
    runAsNonRootGroup: false

    # Whether to create a security context for Pods containing the runAsUser
    # and fsGroup values defined below.
    enabled: false

    # runAsUser must be an integer between 1000 and 65533.
    runAsUser: 1000

    # Defining fsGroup in a security context causes volumes mounted into the
    # containers (including those defined by secrets and config maps) to be
    # owned by the specified group ID, which is also added as a supplementary
    # group to the runtime user. This allows a non-root user and group to read,
    # write, and execute files with permissions 440, 660, and 770.
    fsGroup: 1000

    # Whether to create SecurityContext for containers
    enabledOnContainer: false

    # Specify additional container capabilities such as "NET_ADMIN"
    # Object of type Capabilities v1 core
    # ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#capabilities-v1-core
    capabilities:
      add: []
      drop: []

    # Run container in privileged mode. Processes in privileged containers are
    # essentially equivalent to root on the host
    privileged: false

    # Whether a process can gain more privileges than its parent process. This
    # bool directly controls if the "no_new_privs" flag will be set on the
    # container process
    allowPrivilegeEscalation: false

  ## Specify one or more configMaps to import Environment Variables from
  # Ex:  configMapRef: [ myConfigMap, myOtherConfigMap ]
  envFrom:
    configMapRef: []

  ## Admin options
  # These are applied using the nuoadmin startup command
  # Add these values as appropriate for this domain
  options:
    # this high reconnect timeout is necessary because an admin can be
    # rescheduled on a different Node and a reconnecting engine will not
    # connect to it until the stale DNS entry in its local cache expires,
    # which has a default TTL of 30 seconds
    pendingReconnectTimeout: 60000
    # this is necessary because killed engine Pods may not generate a TCP_RST
    # packet to close the admin connection, leaving a database process entry
    # in the domain state that has no running Pod associated with it
    processLivenessCheckSec: 30
    # increase maximum message size that can be sent between admin processes;
    # if catching up a server using a snapshot, we may have to serialize our
    # entire Raft state into one message; set maximum message size to 1GB to
    # allow Raft state to grow to 1GB
    thrift.message.max: "1073741824"
    # force reconnecting processes that are not in the domain state to shut
    # themselves down
    evictUnknownProcesses: true
    # increase leader assignment timeout to account for maximum scheduling delay
    # of 5 minutes in K8s; set the default value to 15 minutes (3x back-off
    # delay) which should be enough for most databases
    leaderAssignmentTimeout: "900000"

  ## nuodb-admin resource requests and limits
  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}
    # limits:
    #   cpu: 10m
    #   memory: 16Mi
    # requests:
    #   cpu: 10m
    #   memory: 16Mi

  # Custom NuoDB configuration files path
  configFilesPath: /etc/nuodb/

  # NuoDB is a licensed product for Enterprise Edition.
  # Obtain your license from NuoDB support.
  #
  # You can provide the license via a configFile by using:
  #
  # - Helm CLI parameter
  # - Specify in this values.yaml file
  #
  # To specify from the CLI:
  #
  # --set admin.configFiles.nuodb\\.lic=<BASE64-TEXT-HERE>
  #
  configFiles: {}
    # nuodb.lic: |-
    #   "PUT YOUR BASE64 ENCODED LICENSE CONTENT HERE"

  # Recommended default admin affinity:
  # affinity: {}
  # nodeSelector: {}
  # tolerations: []

  # tlsCACert:
  #   secret: nuodb-ca-cert
  #   key: ca.cert
  # tlsKeyStore:
  #   secret: nuodb-keystore
  #   key: nuoadmin.p12
  #   password: changeIt
  # tlsTrustStore:
  #   secret: nuodb-truststore
  #   key: nuoadmin-truststore.p12
  #   password: changeIt
  # tlsClientPEM:
  #   secret: nuodb-client-pem
  #   key: nuocmd.pem

  serviceSuffix:
    clusterip: clusterip
    balancer: balancer
    nodeport: nodeport

  # Some clusters require longer readiness probe timeouts
  readinessTimeoutSeconds: 5

  # These annotations will pass through to the pod as supplied, useful for integrating 3rd party products such as Vault.
  podAnnotations: {}
    # vault.hashicorp.com/agent-inject: true

  ## Transparent Data Encryption (TDE) secrets
  # Storage passwords can be managed and stored as Kubernetes
  # secrets. TDE secrets for all databases should be created and 
  # provided before deploying NuoDB. For example:
  #   kubectl create secret generic demo-tde-secret -n nuodb \
  #     --from-literal target='topSecret'
  #
  # Note: TDE should be enabled on database layer using
  #   SQL> alter database change encryption type AES128;
  #
  # Storage password rotation is performed by updating the secret and 
  # providing the new target and historical (optional) passwords. 
  # The historical passwords are used for restoring old backup sets. 
  # For example:
  #   kubectl create secret generic demo-tde-secret -n nuodb \
  #     --from-literal target='superSecret' \
  #     --from-literal historical-20201110='topSecret' \
  #     --dry-run=client -o yaml | kubectl apply -f -
  tde:
    secrets: {}
      # demo: demo-tde-secret
    storagePasswordsDir: /etc/nuodb/tde

  # A list of evicted servers excluded from RAFT consensus. Used during disaster recovery
  # consult https://doc.nuodb.com/nuodb/latest/database-administration/recovering-from-a-lost-majority/
  evicted:
    servers: []

  # Custom labels attached to the Kubernetes resources installed by this Helm
  # Chart; the labels are immutable and can't be changed with Helm upgrade; for
  # allowed syntax and character sets, please check
  # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set
  resourceLabels: {}

  legacy:
    loadBalancerJob:
      enabled: false

nuocollector:
  enabled: false
  image:
    registry: docker.io
    repository: nuodb/nuodb-collector
    tag: 1.1.0
    pullPolicy: IfNotPresent
  watcher:
    registry: docker.io
    repository: kiwigrid/k8s-sidecar
    tag: 1.10.8
    pullPolicy: IfNotPresent

  # Kubernetes resource requests and limits used for the nuocollector sidecar
  # container
  # ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources: {}

  plugins:
    ## NuoDB Collector compatible plugins specific for admin services
    admin: {}
